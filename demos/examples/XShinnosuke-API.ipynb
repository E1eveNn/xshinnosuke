{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ->->->->->->->->->->->->->->-> Welcome <-<-<-<-<-<-<-<-<-<-<-<-<-<-"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![shinnosuke](https://ss0.bdstatic.com/70cFvHSh_Q1YnxGkpoWK1HF6hhy/it/u=1784511497,119911411&fm=26&gp=0.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Contents</h1>\n",
    "<ol>\n",
    "    <li><h2><a href=\"#layer\">Layer</a></h2>\n",
    "        <ul>\n",
    "            <li><h3><a href=\"#input\">Input</a></h3></li>\n",
    "            <li><h3><a href=\"#dense\">Dense</a></h3></li>\n",
    "            <li><h3><a href=\"#flatten\">Flatten</a></h3></li>\n",
    "            <li><h3><a href=\"#pad\">ZeroPadding2D</a></h3></li>\n",
    "            <li><h3><a href=\"#conv\">Conv2D</a></h3></li>\n",
    "            <li><h3><a href=\"#maxpool\">MaxPooling2D</a></h3></li>\n",
    "            <li><h3><a href=\"#meanpool\">MeanPooling2D</a></h3></li>\n",
    "            <li><h3><a href=\"#act\">Activation</a></h3></li>\n",
    "            <li><h3><a href=\"#reshape\">Reshape</a></h3></li>\n",
    "            <li><h3><a href=\"#dropout\">Dropout</a></h3></li>\n",
    "            <li><h3><a href=\"#bn\">Batch Normalization</a></h3></li>\n",
    "            <li><h3><a href=\"#ln\">Layer Normalization</a></h3></li>\n",
    "            <li><h3><a href=\"#gn\">Group Normalization</a></h3></li>\n",
    "            <li><h3><a href=\"#embed\">Embedding</a></h3></li>\n",
    "            <li><h3><a href=\"#rnn\">SimpleRNN</a></h3></li>\n",
    "            <li><h3><a href=\"#lstm\">LSTM</a></h3></li>\n",
    "            <li><h3><a href=\"#timedist\">TimeDistributed</a></h3></li>\n",
    "        </ul>\n",
    "    </li>\n",
    "    <li><div></div><h2><a href=\"#node\">Node</a></h2>\n",
    "        <ul>\n",
    "            <li><h3><a href=\"#variable\">Variable</a></h3></li>\n",
    "            <li><h3><a href=\"#constant\">Constant</a></h3></li>\n",
    "        </ul>\n",
    "    </li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 id=\"layer\">Layer</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"color: red\" id=\"input\"><i>- Input(input_shape: Tuple,  data: ndarray = None, **kwargs)</i></div>\n",
    "\n",
    "+ input_shape: input data's shape, for example, (None, C, H, W) or (None, features).\n",
    "+ data: this layer's input and output tensor's value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************************************************************************************************************************\n",
      "Layer(type)                              Output Shape                             Param        Connected to   \n",
      "########################################################################################################################\n",
      "input0 (Input)                           (None, 10, 5, 5)                         0            \n",
      "              \n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "************************************************************************************************************************\n",
      "Total params: 0\n",
      "Trainable params: 0\n",
      "Non-trainable params: 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from xshinnosuke.models import Model\n",
    "from xshinnosuke.layers import Input\n",
    "\n",
    "X = Input(input_shape=(10, 5, 5))\n",
    "model = Model(inputs=X, outputs=X)\n",
    "model.compile(optimizer='sgd', loss='mse')\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"color: red\" id=\"dense\"><i>- Dense(out_features: int, out_features, activation=None, use_bias=True, kernel_initializer='normal', bias_initializer='zeros', kernel_regularizer=None, **kwargs)</i></div>\n",
    "\n",
    "+ out_features: out feature numbers.\n",
    "\n",
    "+ kernel_initializer: kernel initialize method. see details in <a href='#Initializers'>Initializers</a>\n",
    "\n",
    "+ bias_initializer: bias initialize method. see details in <a href='#Initializers'>Initializers</a>\n",
    "\n",
    "+ activation: activation function. see details in <a href='#Activations'>Activations</a>\n",
    "\n",
    "+ kernel_regularizer: not implemented."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************************************************************************************************************************\n",
      "Layer(type)                              Output Shape                             Param        Connected to   \n",
      "########################################################################################################################\n",
      "dense0 (Dense)                           (None, 100)                              50100        \n",
      "              \n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "dense1 (Dense)                           (None, 10)                               1010         dense0         \n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "************************************************************************************************************************\n",
      "Total params: 51110\n",
      "Trainable params: 51110\n",
      "Non-trainable params: 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from xshinnosuke.models import Sequential\n",
    "from xshinnosuke.layers import Dense\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(out_features=100, input_shape=(500, ), activation='relu'))\n",
    "model.add(Dense(out_features=10))\n",
    "model.compile(loss='mse', optimizer='adam')\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"color: red\" id=\"flatten\"><i>- Flatten(out_dim: int = 2, **kwargs)</i></div>\n",
    "\n",
    "+ out_dim: after flatten, the output data's dimension. for example, input data's shape is (N, C, H, W), out_dim = 2 will convert output data's shape to (N, $C \\times H \\times W$) and out_dim = 3 will convert output data's shape to (N, C, $H \\times W$)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************************************************************************************************************************\n",
      "Layer(type)                              Output Shape                             Param        Connected to   \n",
      "########################################################################################################################\n",
      "input0 (Input)                           (None, 10, 5, 8)                         0            \n",
      "              \n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "flatten0 (Flatten)                       (None, 400)                              0            input0         \n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "************************************************************************************************************************\n",
      "Total params: 0\n",
      "Trainable params: 0\n",
      "Non-trainable params: 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from xshinnosuke.models import Model\n",
    "from xshinnosuke.layers import Flatten\n",
    "from xshinnosuke.layers import Input\n",
    "\n",
    "X_input = Input(input_shape=(10, 5, 8))\n",
    "X = Flatten(start=1)(X_input)\n",
    "model = Model(inputs=X_input, outputs=X)\n",
    "model.compile(optimizer='sgd', loss='mse')\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"color: red\" id=\"pad\"><i>- ZeroPadding2D(pad_size: Tuple, **kwargs)</i></div>\n",
    "\n",
    "+ pad_size: for example, (1, 1), which means pad input(N, C, H, W) to (N, C, H+2, W+2)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************************************************************************************************************************\n",
      "Layer(type)                              Output Shape                             Param        Connected to   \n",
      "########################################################################################################################\n",
      "input0 (Input)                           (None, 10, 5, 5)                         0            \n",
      "              \n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "zeropadding2d0 (ZeroPadding2D)           (None, 10, 9, 9)                         0            input0         \n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "************************************************************************************************************************\n",
      "Total params: 0\n",
      "Trainable params: 0\n",
      "Non-trainable params: 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from xshinnosuke.models import Model\n",
    "from xshinnosuke.layers import ZeroPadding2D\n",
    "from xshinnosuke.layers import Input\n",
    "\n",
    "X_input = Input(input_shape=(10, 5, 5))\n",
    "X = ZeroPadding2D(pad_size=(2, 2))(X_input)\n",
    "model = Model(inputs=X_input, outputs=X)\n",
    "model.compile(optimizer='sgd', loss='mse')\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"color: red\" id=\"conv\"><i>- Conv2D(filter_nums: int, filter_size: Tuple, input_shape: Tuple = None, stride: int = 1, padding: str = 'VALID', activation = 'linear',initializer = 'Normal', **kwargs)</i></div>\n",
    "\n",
    "+ filter_nums: filter's numbers.\n",
    "\n",
    "+ filter_size: filter's size. for example, (3, 3) or 3.\n",
    "\n",
    "+ input_shape: must specify if this is the first layer of network.\n",
    "\n",
    "+ stride: convolution stride.\n",
    "\n",
    "+ padding: 'SAME' or 'VALID', 'VALID' means no padding, 'SAME' means pad input to get the same output size as input.\n",
    "\n",
    "+ activation: activation function. see details in <a href='#Activations'>Activations</a>\n",
    "\n",
    "+ initializer: kernel and bias initialize method. see details in <a href='#Initializers'>Initializers</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************************************************************************************************************************\n",
      "Layer(type)                              Output Shape                             Param        Connected to   \n",
      "########################################################################################################################\n",
      "input0 (Input)                           (None, 3, 24, 24)                        0            \n",
      "              \n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "conv2d0 (Conv2D)                         (None, 16, 22, 22)                       432          input0         \n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "************************************************************************************************************************\n",
      "Total params: 432\n",
      "Trainable params: 432\n",
      "Non-trainable params: 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from xshinnosuke.models import Model\n",
    "from xshinnosuke.layers import Conv2D\n",
    "from xshinnosuke.layers import Input\n",
    "\n",
    "X_input = Input(input_shape=(3, 24, 24))\n",
    "X = Conv2D(out_channels=16, kernel_size=(3, 3), stride=1, padding='VALID', activation='relu')(X_input)\n",
    "model = Model(inputs=X_input, outputs=X)\n",
    "model.compile(optimizer='sgd', loss='bce')\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"color: red\" id=\"maxpool\"><i>- MaxPooling2D(pool_size: Tuple, stride: int = None, **kwargs)</i></div>\n",
    "\n",
    "+ pool_size: pooling kernel size, for example (2, 2) means apply max pooling in every 2 x 2 area.\n",
    "+ stride: pooling stride."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"color: red\" id=\"meanpool\"><i>- AvgPooling2D(pool_size: Tuple, stride: int = None, **kwargs)</i></div>\n",
    "\n",
    "+ pool_size: pooling kernel size, for example (2, 2) means apply mean pooling in every 2 x 2 area.\n",
    "+ stride: pooling stride."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************************************************************************************************************************\n",
      "Layer(type)                              Output Shape                             Param        Connected to   \n",
      "########################################################################################################################\n",
      "input0 (Input)                           (None, 3, 24, 24)                        0            \n",
      "              \n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "maxpooling2d0 (MaxPooling2D)             (None, 3, 12, 12)                        0            input0         \n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "avgpooling2d0 (AvgPooling2D)             (None, 3, 6, 6)                          0            maxpooling2d0  \n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "************************************************************************************************************************\n",
      "Total params: 0\n",
      "Trainable params: 0\n",
      "Non-trainable params: 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from xshinnosuke.models import Model\n",
    "from xshinnosuke.layers import MaxPooling2D, AvgPooling2D\n",
    "from xshinnosuke.layers import Input\n",
    "\n",
    "X_input = Input(input_shape=(3, 24, 24))\n",
    "X = MaxPooling2D(kernel_size=2)(X_input)\n",
    "X = AvgPooling2D(kernel_size=2)(X)\n",
    "model = Model(inputs=X_input, outputs=X)\n",
    "model.compile(optimizer='sgd', loss='bce')\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"color: red\" id=\"act\"><i>- Activation(act_name='relu')</i></div>\n",
    "\n",
    "+ act_name: activation function name, support ReLU, Sigmoid, etc. see details in <a href='#Activations'>Activations</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************************************************************************************************************************\n",
      "Layer(type)                              Output Shape                             Param        Connected to   \n",
      "########################################################################################################################\n",
      "input0 (Input)                           (None, 3, 24, 24)                        0            \n",
      "              \n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "activation0 (Activation)                 (None, 3, 24, 24)                        0            input0         \n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "activation1 (Activation)                 (None, 3, 24, 24)                        0            activation0    \n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "activation2 (Activation)                 (None, 3, 24, 24)                        0            activation1    \n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "************************************************************************************************************************\n",
      "Total params: 0\n",
      "Trainable params: 0\n",
      "Non-trainable params: 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from xshinnosuke.models import Model\n",
    "from xshinnosuke.layers import Activation\n",
    "from xshinnosuke.layers import Input\n",
    "\n",
    "X_input = Input(input_shape=(3, 24, 24))\n",
    "X = Activation('relu')(X_input)\n",
    "X = Activation('sigmoid')(X)\n",
    "X = Activation('softmax')(X)\n",
    "model = Model(inputs=X_input, outputs=X)\n",
    "model.compile(optimizer='sgd', loss='cross_entropy')\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"color: red\" id=\"dropout\"><i>- Dropout(keep_prob)</i></div>\n",
    "\n",
    "+ keep_prob:  probability of keeping a unit active."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************************************************************************************************************************\n",
      "Layer(type)                              Output Shape                             Param        Connected to   \n",
      "########################################################################################################################\n",
      "input0 (Input)                           (None, 500)                              0            \n",
      "              \n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "dropout0 (Dropout)                       (None, 500)                              0            input0         \n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "************************************************************************************************************************\n",
      "Total params: 0\n",
      "Trainable params: 0\n",
      "Non-trainable params: 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from xshinnosuke.models import Model\n",
    "from xshinnosuke.layers import Dropout\n",
    "from xshinnosuke.layers import Input\n",
    "\n",
    "X_input = Input(input_shape=(500, ))\n",
    "X = Dropout(keep_prob=0.5)(X_input)\n",
    "model = Model(inputs=X_input, outputs=X)\n",
    "model.compile(optimizer='sgd', loss='mse')\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"color: red\" id=\"bn\"><i>- Batch Normalization(epsilon=1e-6, momentum=0.9, axis=1, gamma_initializer='ones', beta_initializer='zeros', moving_mean_initializer='zeros', moving_variance_initializer='ones')</i></div>\n",
    "$$\n",
    "u_B = \\frac{1}{m} \\sum \\limits_{i=1}^m x_i  \\quad \\quad mini-batch \\quad mean\n",
    "\\\\\n",
    "\\sigma_B = \\frac{1}{m} \\sum \\limits_{i=1}^m (x_i - u_B)^2  \\quad \\quad mini-batch \\quad variance\n",
    "\\\\\n",
    "\\hat x_i = \\frac{x_i - u_B}{\\sqrt{\\sigma_B^2 + \\epsilon}}   \\quad \\quad normalize\n",
    "\\\\\n",
    "y_i = \\gamma \\hat x_i + \\beta  \\quad \\quad scale \\quad and \\quad shift\n",
    "$$\n",
    "\n",
    "\n",
    "+ epsilon:  $\\epsilon$ value.\n",
    "+ momentum: at training time, we use moving averages to update $u_B \\rightarrow$ $moving\\_u = momentum * moving\\_u + (1 - momentum) * u_B$ and $\\sigma_B \\rightarrow  moving\\_\\sigma = momentum * moving\\_\\sigma + (1 - momentum) * \\sigma_B$ \n",
    "+ axis: use normalization on which axis, for Dense Layer, it should be 1 or -1, for Convolution Layer, it should be 1.\n",
    "+ gamma_initializer: initialize $\\gamma$ method. see details in <a href='#Initializers'>Initializers</a>\n",
    "+ beta_initializer: initialize $\\beta$ method. see details in <a href='#Initializers'>Initializers</a>\n",
    "+ moving_mean_initializer: initialize $moving\\_u$ method. see details in <a href='#Initializers'>Initializers</a>\n",
    "+ moving_variance_initializer: initialize $moving\\_\\sigma$ method. see details in <a href='#Initializers'>Initializers</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"color: red\" id=\"ln\"><i>- Layer Normalization(epsilon=1e-10, gamma_initializer='ones', beta_initializer='zeros')</i></div>\n",
    "$$\n",
    "u = \\frac{1}{CHW} \\sum \\limits_{i=1}^C \\sum \\limits_{j=1}^H \\sum \\limits_{k=1}^W x_{ijk}  \\quad \\quad sample \\quad mean\n",
    "\\\\\n",
    "\\sigma = \\frac{1}{CHW} \\sum \\limits_{i=1}^C \\sum \\limits_{j=1}^H \\sum \\limits_{k=1}^W (x_{ijk} - u)^2  \\quad \\quad sample \\quad variance\n",
    "\\\\\n",
    "\\hat x = \\frac{x - u}{\\sqrt{\\sigma^2 + \\epsilon}}   \\quad \\quad normalize\n",
    "\\\\\n",
    "y = \\gamma \\hat x + \\beta  \\quad \\quad scale \\quad and \\quad shift\n",
    "$$\n",
    "\n",
    "\n",
    "+ epsilon:  $\\epsilon$ value.\n",
    "+ gamma_initializer: initialize $\\gamma$ method. see details in <a href='#Initializers'>Initializers</a>\n",
    "+ beta_initializer: initialize $\\beta$ method. see details in <a href='#Initializers'>Initializers</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"color: red\" id=\"gn\"><i>- Group Normalization(epsilon=1e-5, G=16,gamma_initializer='ones', beta_initializer='zeros')</i></div>\n",
    "split channel into G groups, for each group, applying layer normalization separately.\n",
    "$$\n",
    "\\\\\n",
    "u = \\frac{1}{CHW} \\sum \\limits_{i=1}^C \\sum \\limits_{j=1}^H \\sum \\limits_{k=1}^W x_{ijk}  \\quad \\quad sample \\quad mean\n",
    "\\\\\n",
    "\\sigma = \\frac{1}{CHW} \\sum \\limits_{i=1}^C \\sum \\limits_{j=1}^H \\sum \\limits_{k=1}^W (x_{ijk} - u)^2  \\quad \\quad sample \\quad variance\n",
    "\\\\\n",
    "\\hat x = \\frac{x - u}{\\sqrt{\\sigma^2 + \\epsilon}}   \\quad \\quad normalize\n",
    "\\\\\n",
    "y = \\gamma \\hat x + \\beta  \\quad \\quad scale \\quad and \\quad shift\n",
    "$$\n",
    "\n",
    "\n",
    "+ epsilon:  $\\epsilon$ value.\n",
    "+ G: group numbers.\n",
    "+ gamma_initializer: initialize $\\gamma$ method. see details in <a href='#Initializers'>Initializers</a>\n",
    "+ beta_initializer: initialize $\\beta$ method. see details in <a href='#Initializers'>Initializers</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************************************************************************************************************************\n",
      "Layer(type)                              Output Shape                             Param        Connected to   \n",
      "########################################################################################################################\n",
      "input0 (Input)                           (None, 16, 5, 5)                         0            \n",
      "              \n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "batchnormalization0 (BatchNormalization) (None, 16, 5, 5)                         32           input0         \n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "layernormalization0 (LayerNormalization) (None, 16, 5, 5)                         800          batchnormalization0\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "groupnormalization0 (GroupNormalization) (None, 16, 5, 5)                         32           layernormalization0\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "************************************************************************************************************************\n",
      "Total params: 864\n",
      "Trainable params: 864\n",
      "Non-trainable params: 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from xshinnosuke.models import Model\n",
    "from xshinnosuke.layers import BatchNormalization, LayerNormalization, GroupNormalization\n",
    "from xshinnosuke.layers import Input\n",
    "\n",
    "X_input = Input(input_shape=(16, 5, 5))\n",
    "X = BatchNormalization()(X_input)\n",
    "X = LayerNormalization()(X)\n",
    "X = GroupNormalization()(X)\n",
    "model = Model(inputs=X_input, outputs=X)\n",
    "model.compile(optimizer='sgd', loss='mse')\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"color: red\" id=\"embed\"><i>- Embedding(input_dim, output_dim,embeddings_initializer='uniform', mask_zero=False, input_length=None, **kwargs)</i></div>\n",
    "\n",
    "+ input_dim: to embedded dimension, for example, input data shape is (N, T), input_dim is the max value.\n",
    "+ out_dim: after embedding dimension, for example, out_dim = E, input data (N, T) after embedding's shape is (N, T, E).\n",
    "+ embeddings_initializer: embedding kernel initialize method. see details in <a href='#Initializers'>Initializers</a>\n",
    "+ mask_zero: use masks.\n",
    "+ input_length: must specify if this layer is first layer of network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************************************************************************************************************************\n",
      "Layer(type)                              Output Shape                             Param        Connected to   \n",
      "########################################################################################################################\n",
      "embedding0 (Embedding)                   (None, 30, 200)                          1000000      \n",
      "              \n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "************************************************************************************************************************\n",
      "Total params: 1000000\n",
      "Trainable params: 1000000\n",
      "Non-trainable params: 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from xshinnosuke.models import Sequential\n",
    "from xshinnosuke.layers import Embedding\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=5000, output_dim=200, input_length=30))\n",
    "model.compile(optimizer='sgd', loss='mse')\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"color: red\" id=\"rnn\"><i>- SimpleRNN(units, activation='tanh', initializer='glorotuniform', recurrent_initializer='orthogonal', return_sequences=False, return_state=False, stateful=False, **kwargs)</i></div>\n",
    "\n",
    "$$\n",
    "z^t = W_{aa}\\cdot a^{t-1} + W_{xa}\\cdot x^t +b_a\n",
    "\\\\\n",
    "a^t = activation(z^t)\n",
    "$$\n",
    "\n",
    "+ units: rnn hidden unit numbers, for example, units = a, input data (N, T, L) after rnn will output (N, T, a).\n",
    "+ activation: activation method. see details in <a href='#Activations'>Activations</a>\n",
    "+ initializer: $W_{xa}$ initialize method. see details in <a href='#Initializers'>Initializers</a>\n",
    "+ recurrent_initializer: $W_{aa}$ initialize method. see details in <a href='#Initializers'>Initializers</a>\n",
    "+ return_sequences: if True, return all timesteps a $\\rightarrow$ $[a^1, a^2,..., a^t]$; if False, return the last timesteps $a^t$.\n",
    "+ return_state: if True, return return_sequences' result and all timesteps a.\n",
    "+ stateful: if True, use last time $a^t$ to initialize this time $a^1$; if False, use 0 to initialize this time $a^1$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************************************************************************************************************************\n",
      "Layer(type)                              Output Shape                             Param        Connected to   \n",
      "########################################################################################################################\n",
      "input0 (Input)                           (None, 30, 200)                          0            \n",
      "              \n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "simplernn0 (SimpleRNN)                   (None, 50)                               12550        input0         \n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "************************************************************************************************************************\n",
      "Total params: 12550\n",
      "Trainable params: 12550\n",
      "Non-trainable params: 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from xshinnosuke.models import Model\n",
    "from xshinnosuke.layers import SimpleRNN\n",
    "from xshinnosuke.layers import Input\n",
    "\n",
    "X_input = Input(input_shape=(30, 200))\n",
    "X = SimpleRNN(units=50)(X_input)\n",
    "model = Model(inputs=X_input, outputs=X)\n",
    "model.compile(optimizer='sgd', loss='mse')\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"color: red\" id=\"lstm\"><i>- LSTM(units, activation='tanh', recurrent_activation='sigmoid', initializer='glorotuniform', recurrent_initializer='orthogonal', unit_forget_bias=True, return_sequences=False, return_state=False, stateful=False, **kwargs)</i></div>\n",
    "\n",
    "at every timesteps\n",
    "\n",
    "$$\n",
    "i^t = recurrent\\_activation(W_i[a^{t-1}, x^t] + b_i)\n",
    "\\\\\n",
    "f^t = recurrent\\_activation(W_f[a^{t-1}, x^t] + b_f)\n",
    "\\\\\n",
    "\\tilde c^t = activation(W_c[a^{t-1}, x^t] + b_c)\n",
    "\\\\\n",
    "c^t = f^t \\cdot c^{t-1} + i^t \\cdot \\tilde c^t\n",
    "\\\\\n",
    "o^t = recurrent\\_activation(W_o[a^{t-1}, x^t] + b_o)\n",
    "\\\\\n",
    "a^t = o^t \\cdot tanh(c^t)\n",
    "$$\n",
    "\n",
    "+ units: lstm hidden unit numbers.\n",
    "+ activation: activation method. see details in <a href='#Activations'>Activations</a>\n",
    "+ recurrent_activation: activation method. see details in <a href='#Activations'>Activations</a>\n",
    "+ initializer: $W_{xa}$ initialize method. see details in <a href='#Initializers'>Initializers</a>\n",
    "+ recurrent_initializer: $W_{aa}$ initialize method. see details in <a href='#Initializers'>Initializers</a>\n",
    "+ unit_forget_bias: if True, initialize $f^t$ bias $b_f$ as 1, else 0.\n",
    "+ return_sequences: if True, return all timesteps a $\\rightarrow$ $[a^1, a^2,..., a^t]$; if False, return the last timesteps $a^t$.\n",
    "+ return_state: if True, return return_sequences' result and all timesteps a.\n",
    "+ stateful: if True, use last time $a^t$ to initialize this time $a^1$; if False, use 0 to initialize this time $a^1$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************************************************************************************************************************\n",
      "Layer(type)                              Output Shape                             Param        Connected to   \n",
      "########################################################################################################################\n",
      "input0 (Input)                           (None, 30, 200)                          0            \n",
      "              \n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "lstm0 (LSTM)                             (None, 30, 50)                           50200        input0         \n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "************************************************************************************************************************\n",
      "Total params: 50200\n",
      "Trainable params: 50200\n",
      "Non-trainable params: 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from xshinnosuke.models import Model\n",
    "from xshinnosuke.layers import LSTM\n",
    "from xshinnosuke.layers import Input\n",
    "\n",
    "X_input = Input(input_shape=(30, 200))\n",
    "X = LSTM(units=50, return_sequences=True)(X_input)\n",
    "model = Model(inputs=X_input, outputs=X)\n",
    "model.compile(optimizer='sgd', loss='mse')\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"color: red\" id=\"timedist\"><i>- TimeDistributed(layer, **kwargs)</i></div>\n",
    "\n",
    "+ layer: to apply time distributed layer.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************************************************************************************************************************\n",
      "Layer(type)                              Output Shape                             Param        Connected to   \n",
      "########################################################################################################################\n",
      "input0 (Input)                           (None, 25, 97)                           0            \n",
      "              \n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "lstm0 (LSTM)                             (None, 25, 100)                          79200        input0         \n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "timedistributed0 (TimeDistributed)       (None, 25, 50)                           5050         lstm0          \n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "************************************************************************************************************************\n",
      "Total params: 84250\n",
      "Trainable params: 84250\n",
      "Non-trainable params: 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from xshinnosuke.layers import Input, Dense, LSTM, TimeDistributed\n",
    "from xshinnosuke.models import Model\n",
    "\n",
    "X_input = Input(input_shape=(25, 97))\n",
    "X = LSTM(units=100, return_sequences=True, stateful=True)(X_input)\n",
    "X = TimeDistributed(Dense(50))(X)\n",
    "model = Model(inputs=X_input, outputs=X)\n",
    "model.compile(optimizer='sgd', loss='mse')\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 id=\"node\">Node</h2>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
